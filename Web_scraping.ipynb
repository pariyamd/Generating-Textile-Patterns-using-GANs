{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VG8o5Qod8t6L"
   },
   "source": [
    "Web scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NyJ6k5jhBSuf"
   },
   "source": [
    "https://www.thepythoncode.com/article/download-web-page-images-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_sfBLcZd8-zy",
    "outputId": "caef3a9e-720e-4950-f1ef-6b52c97d829f"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from urllib.parse import urljoin, urlparse\n",
    "import re\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "5qtg7MN59CCH"
   },
   "outputs": [],
   "source": [
    "def is_valid(url):\n",
    "    \"\"\"\n",
    "    Checks whether `url` is a valid URL.\n",
    "    \"\"\"\n",
    "    if \"preview\" not in url:\n",
    "      return False\n",
    "    parsed = urlparse(url)\n",
    "    return bool(parsed.netloc) and bool(parsed.scheme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V6OgRpXrZLav",
    "outputId": "d7a8418e-844b-4b6e-ca2e-8bd1a0cd9695"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "m8cVEFxZCjM3"
   },
   "outputs": [],
   "source": [
    "soup = bs(requests.get(\"https://patternbank.com/studio?image_format=vector&in_repeat=1&licence=stock&page=1\").content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "YQ2Td3qlC83K"
   },
   "outputs": [],
   "source": [
    "def get_all_images(url):\n",
    "    \"\"\"\n",
    "    Returns all image URLs on a single `url`\n",
    "    \"\"\"\n",
    "    soup = bs(requests.get(url).content, \"html.parser\")\n",
    "    urls = []\n",
    "    labels=[]\n",
    "    for img in soup.findAll(\"img\",{\"class\":\"img-responsive\"}):\n",
    "        img_url = img.attrs.get(\"data-src\")\n",
    "        \n",
    "        if not img_url:\n",
    "            # if img does not contain src attribute, just skip\n",
    "            continue\n",
    "            # make the URL absolute by joining domain with the URL that is just extracted\n",
    "        # print(img_url)\n",
    "        img_url = urljoin(url, img_url) \n",
    "        \n",
    "        try:\n",
    "            pos = img_url.index(\"?\")\n",
    "            img_url = img_url[:pos]\n",
    "            # print(img_url)\n",
    "        except ValueError:\n",
    "            pass\n",
    "        # finally, if the url is valid\n",
    "        if is_valid(img_url):\n",
    "            # print(\"is valid\\n\")\n",
    "    \n",
    "            page_url=urljoin(url,img.parent[\"href\"])\n",
    "            \n",
    "            name=f\"{page_url.rsplit('/', 1)[-1]}.jpg\"\n",
    "            soup_page = bs(requests.get(page_url).content, \"html.parser\")\n",
    "            categories=[]\n",
    "            all_category_spans=soup_page.findAll('b', text=re.compile('Categories:'))\n",
    "            if len(all_category_spans)==0:\n",
    "              continue\n",
    "            for span in all_category_spans[0].parent.findAll(\"span\"):\n",
    "              categories.append(span.text)\n",
    "            \n",
    "            urls.append([img_url,name,categories])\n",
    "            # labels.append(categories)\n",
    "        # else:\n",
    "        #   print(\"is not valid\\n\")\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "v69kF_oiDJUS"
   },
   "outputs": [],
   "source": [
    "# test_urls=get_all_images(\"https://patternbank.com/studio?image_format=vector&in_repeat=1&licence=stock&page=1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "CCbkojSY9ELG"
   },
   "outputs": [],
   "source": [
    "# def get_all_images(url):\n",
    "#     \"\"\"\n",
    "#     Returns all image URLs on a single `url`\n",
    "#     \"\"\"\n",
    "#     soup = bs(requests.get(url).content, \"html.parser\")\n",
    "#     urls = []\n",
    "#     labels=[]\n",
    "#     for img in soup.find(\"div\",{\"class\":\"row design-thumbnails product-image-grid js-image-grid\"}).findAll(\"img\"):\n",
    "#         img_url = img.attrs.get(\"src\")\n",
    "        \n",
    "#         if not img_url:\n",
    "#             # if img does not contain src attribute, just skip\n",
    "#             continue\n",
    "#             # make the URL absolute by joining domain with the URL that is just extracted\n",
    "#         # print(img_url)\n",
    "#         img_url = urljoin(url, img_url) \n",
    "        \n",
    "#         try:\n",
    "#             pos = img_url.index(\"?\")\n",
    "#             img_url = img_url[:pos]\n",
    "#             # print(img_url)\n",
    "#         except ValueError:\n",
    "#             pass\n",
    "#         # finally, if the url is valid\n",
    "#         if is_valid(img_url):\n",
    "#             # print(\"is valid\\n\")\n",
    "#             print(img_url)\n",
    "#             print()\n",
    "#             page_url=urljoin(url,img.parent[\"href\"])\n",
    "            \n",
    "#             name=f\"{page_url.rsplit('/', 1)[-1]}.jpg\"\n",
    "#             soup_page = bs(requests.get(page_url).content, \"html.parser\")\n",
    "#             categories=[]\n",
    "#             all_category_spans=soup_page.findAll('b', text=re.compile('Categories:'))\n",
    "#             if len(all_category_spans)==0:\n",
    "#               continue\n",
    "#             for span in all_category_spans[0].parent.findAll(\"span\"):\n",
    "#               categories.append(span.text)\n",
    "            \n",
    "#             urls.append([img_url,name,categories])\n",
    "#             # labels.append(categories)\n",
    "#         # else:\n",
    "#         #   print(\"is not valid\\n\")\n",
    "#     return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "756EzQvP9G1T"
   },
   "outputs": [],
   "source": [
    "def download(url, pathname,name):\n",
    "    \"\"\"\n",
    "    Downloads a file given an URL and puts it in the folder `pathname`\n",
    "    \"\"\"\n",
    "    # print(url)\n",
    "    # if path doesn't exist, make that path dir\n",
    "    if not os.path.isdir(pathname):\n",
    "        os.makedirs(pathname)\n",
    "    # download the body of response by chunk, not immediately\n",
    "    response = requests.get(url, stream=True)\n",
    "    # get the total file size\n",
    "    file_size = int(response.headers.get(\"Content-Length\", 0))\n",
    "    # get the file name\n",
    "    # filename = os.path.join(pathname, url.split(\"/\")[-1])\n",
    "    filename = os.path.join(pathname,name)\n",
    "    # progress bar, changing the unit to bytes instead of iteration (default by tqdm)\n",
    "    # progress = tqdm(, f\"Downloading {filename}\", total=file_size, unit=\"B\", unit_scale=True, unit_divisor=1024)\n",
    "    with open(filename, \"wb\") as f:\n",
    "        for data in response.iter_content(1024):\n",
    "            # write data read to the file\n",
    "            f.write(data)\n",
    "            # update the progress bar manually\n",
    "            # progress.update(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "q4ox-JNS9XKD"
   },
   "outputs": [],
   "source": [
    "def download_all(imgs, path):\n",
    "    for image_url,name,labels in tqdm(imgs):\n",
    "        # for each image, download it\n",
    "        download(image_url,path,name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ib6-SwYb3V1Y"
   },
   "outputs": [],
   "source": [
    "# len(test_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "9ux4JGSZ2tYZ"
   },
   "outputs": [],
   "source": [
    "# download_all(test_urls,\"/content/drive/MyDrive/fabrics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "LsAPMym2E0nw"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PsTGMPTRmPmt",
    "outputId": "ad48e4df-3c07-4411-9fd1-5d7462e1e54c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/418 [00:00<?, ?it/s]/tmp/ipykernel_18312/3167404411.py:33: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  all_category_spans=soup_page.findAll('b', text=re.compile('Categories:'))\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 418/418 [9:11:42<00:00, 79.19s/it]\n"
     ]
    }
   ],
   "source": [
    "NUM_PAGES=419\n",
    "imgs=[]\n",
    "# get all images\n",
    "for i in tqdm(range(1,NUM_PAGES)):\n",
    "    url=f\"https://patternbank.com/search?button=&licence=stock&page={i}&q=flower&search_type=designs&sort=best-match&utf8=%E2%9C%93\"\n",
    "    imgs.extend(get_all_images(url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "REbzEEgyYvto",
    "outputId": "6f3ae4f2-99e6-4943-a1fd-1cac0031c0da"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41723"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "p5UZIYAehSve"
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "K0BAIeOYvxz1"
   },
   "outputs": [],
   "source": [
    "f = open('floral.pickle', 'wb')\n",
    "pickle.dump(imgs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "QiyWhJy4wDb3"
   },
   "outputs": [],
   "source": [
    "f2 = open('floral.pickle', 'rb')\n",
    "imgs1 = pickle.load(f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41723"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(imgs1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QpWK-Sogg9v7"
   },
   "outputs": [],
   "source": [
    "imgs=list(dict.fromkeys(imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ViQNQxwXgjg7"
   },
   "outputs": [],
   "source": [
    "\n",
    "with open(r'urls.txt', 'w') as fp:\n",
    "    for item in imgs:\n",
    "        fp.write(\"%s\\n\" % item)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OpntgG8XsMNd",
    "outputId": "a262b923-b154-4fd1-f9ec-405e7cd4a9ee"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|█████▎                                                                      | 2898/41723 [11:58<3:47:12,  2.85it/s]"
     ]
    }
   ],
   "source": [
    "# download and save all images\n",
    "download_all(imgs1,\"Floral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "XklxJt1Hi83K"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection1=pd.read_csv(\"selection1_meta_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Ghuy5-KrCwly"
   },
   "outputs": [],
   "source": [
    "path=\"Floral\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "6v9iPWExmKV3"
   },
   "outputs": [],
   "source": [
    "df=pd.DataFrame(imgs1,columns=[\"url\",\"name\",\"labels\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersect=df[df.name.isin(list(set(df[\"name\"]).intersection(set(selection1[\"name\"]))))].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in intersect.name:\n",
    "    try:\n",
    "        os.remove(join(path,filename))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff=df[df.name.isin(list(set(df[\"name\"]).difference(set(selection1[\"name\"]))))].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff.to_csv(\"floral_diff.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Animal_Skins</th>\n",
       "      <th>Animals/Birds</th>\n",
       "      <th>Border</th>\n",
       "      <th>Camouflage</th>\n",
       "      <th>Checks</th>\n",
       "      <th>Conversationals</th>\n",
       "      <th>Ethnic</th>\n",
       "      <th>Floral</th>\n",
       "      <th>Geometric</th>\n",
       "      <th>Nature</th>\n",
       "      <th>Paisleys</th>\n",
       "      <th>Placements</th>\n",
       "      <th>Stripes</th>\n",
       "      <th>Texture</th>\n",
       "      <th>Traditional</th>\n",
       "      <th>Tribal</th>\n",
       "      <th>Tropical</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9462</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9463</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9464</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9465</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9466</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9467 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Abstract  Animal_Skins  Animals/Birds  Border  Camouflage  Checks   \n",
       "0            1             0              0       0           0       0  \\\n",
       "1            1             0              0       0           0       0   \n",
       "2            0             0              0       0           0       0   \n",
       "3            0             0              0       0           0       0   \n",
       "4            0             0              0       0           0       0   \n",
       "...        ...           ...            ...     ...         ...     ...   \n",
       "9462         1             0              0       0           0       0   \n",
       "9463         0             0              0       0           0       0   \n",
       "9464         0             0              0       0           0       0   \n",
       "9465         0             0              0       0           0       0   \n",
       "9466         0             0              0       0           0       0   \n",
       "\n",
       "      Conversationals  Ethnic  Floral  Geometric  Nature  Paisleys   \n",
       "0                   0       0       0          0       0         0  \\\n",
       "1                   0       0       0          0       0         0   \n",
       "2                   0       0       0          1       0         0   \n",
       "3                   0       0       0          1       0         0   \n",
       "4                   0       0       0          1       0         1   \n",
       "...               ...     ...     ...        ...     ...       ...   \n",
       "9462                1       0       0          1       0         0   \n",
       "9463                0       0       1          0       1         0   \n",
       "9464                1       0       0          0       1         0   \n",
       "9465                0       0       1          0       0         0   \n",
       "9466                0       0       0          0       0         0   \n",
       "\n",
       "      Placements  Stripes  Texture  Traditional  Tribal  Tropical  \n",
       "0              0        1        1            0       0         0  \n",
       "1              0        1        0            1       0         0  \n",
       "2              0        1        0            0       0         1  \n",
       "3              0        1        1            0       0         0  \n",
       "4              0        1        0            0       0         0  \n",
       "...          ...      ...      ...          ...     ...       ...  \n",
       "9462           0        1        0            0       0         0  \n",
       "9463           0        1        0            0       0         0  \n",
       "9464           0        1        0            0       0         0  \n",
       "9465           0        1        0            0       0         0  \n",
       "9466           0        1        0            0       0         0  \n",
       "\n",
       "[9467 rows x 18 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dummies=df[\"labels\"].apply(lambda x: \" \".join(x)).str.get_dummies(sep=\" \")\n",
    "label_dummies=label_dummies.drop(\"Skins\",axis=1).rename(columns={\"Animal\": \"Animal_Skins\"})\n",
    "meta=pd.concat([df, label_dummies], axis='columns')\n",
    "label_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IvMHsshxm001"
   },
   "outputs": [],
   "source": [
    "meta.to_csv(\"stripes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dUQqA0b7GGlE"
   },
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, csv, train, test):\n",
    "        self.csv = csv\n",
    "        self.train = train\n",
    "        self.test = test\n",
    "        self.all_image_names = self.csv[:]['Id']\n",
    "        self.all_labels = np.array(self.csv.drop(['Id', 'Genre'], axis=1))\n",
    "        self.train_ratio = int(0.85 * len(self.csv))\n",
    "        self.valid_ratio = len(self.csv) - self.train_ratio\n",
    "        # set the training data images and labels\n",
    "        if self.train == True:\n",
    "            print(f\"Number of training images: {self.train_ratio}\")\n",
    "            self.image_names = list(self.all_image_names[:self.train_ratio])\n",
    "            self.labels = list(self.all_labels[:self.train_ratio])\n",
    "            # define the training transforms\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.ToPILImage(),\n",
    "                transforms.Resize((400, 400)),\n",
    "                transforms.RandomHorizontalFlip(p=0.5),\n",
    "                transforms.RandomRotation(degrees=45),\n",
    "                transforms.ToTensor(),\n",
    "            ])\n",
    "        # set the validation data images and labels\n",
    "        elif self.train == False and self.test == False:\n",
    "            print(f\"Number of validation images: {self.valid_ratio}\")\n",
    "            self.image_names = list(self.all_image_names[-self.valid_ratio:-10])\n",
    "            self.labels = list(self.all_labels[-self.valid_ratio:])\n",
    "            # define the validation transforms\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.ToPILImage(),\n",
    "                transforms.Resize((400, 400)),\n",
    "                transforms.ToTensor(),\n",
    "            ])\n",
    "        # set the test data images and labels, only last 10 images\n",
    "        # this, we will use in a separate inference script\n",
    "        elif self.test == True and self.train == False:\n",
    "            self.image_names = list(self.all_image_names[-10:])\n",
    "            self.labels = list(self.all_labels[-10:])\n",
    "             # define the test transforms\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.ToPILImage(),\n",
    "                transforms.ToTensor(),\n",
    "            ])\n",
    "    def __len__(self):\n",
    "        return len(self.image_names)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image = cv2.imread(f\"../input/movie-classifier/Multi_Label_dataset/Images/{self.image_names[index]}.jpg\")\n",
    "        # convert the image from BGR to RGB color format\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        # apply image transforms\n",
    "        image = self.transform(image)\n",
    "        targets = self.labels[index]\n",
    "        \n",
    "        return {\n",
    "            'image': torch.tensor(image, dtype=torch.float32),\n",
    "            'label': torch.tensor(targets, dtype=torch.float32)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "0Ge2u-ikNZFt"
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import join\n",
    "from zipfile import ZipFile\n",
    "from zipfile import ZIP_DEFLATED\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "ljWaC8CICzqG"
   },
   "outputs": [],
   "source": [
    "files = [join(path,f) for f in listdir(path)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "Re1JHRltDcZB",
    "outputId": "a41e530c-b9fe-4de3-84f4-580f7ba9cd93"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ditsy/560185571-ditsy.jpg'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pisInQlfDlNi",
    "outputId": "c5968997-d285-4852-ec9d-befefff8c5ec"
   },
   "outputs": [],
   "source": [
    "# len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lXTgJqdDCgC5",
    "outputId": "bbf366e6-3978-4d04-f19b-11c8d9116116"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 8324/8324 [00:25<00:00, 321.04it/s]\n"
     ]
    }
   ],
   "source": [
    "with ZipFile(f'stripes.zip', 'w', compression=ZIP_DEFLATED) as handle:\n",
    "  # add all files to the zip\n",
    "  for filepath in tqdm(files):\n",
    "      # add file to the archive\n",
    "      handle.write(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "97ef4sLpD5-9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bi/ala/scratch/pmehrbod/GAN\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
